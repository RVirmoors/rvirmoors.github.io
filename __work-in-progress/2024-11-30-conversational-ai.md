---
layout: post
title: Interactive artworks and conversational AI
---


at a crossroads - AI evangelist vs skeptic substacks.

re-training / finetuning: going from GPT-2 (1.5b params) to even a "small" LLaMA-based model (7b) makes finetuning so much more harder, that it's pretty safe to say it was a waste of time and resources. While the results were not nothing, we ...

not gonna write a coding how-to, chatgpt and bespoke
[helpers](https://app.commanddash.io/agent?github=https://github.com/vocodedev/vocode-core) have replaced that job